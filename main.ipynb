{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9858103c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Writing audio in transcribed_speech.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Writing audio in transcribed_speech.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Launch', 'Graphics', 'AerialView']\n",
      "['on board PSLV on board PSLV ']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>category1</th>\n",
       "      <th>category2</th>\n",
       "      <th>category3</th>\n",
       "      <th>metadata</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Video012-Scene-191.mp4</td>\n",
       "      <td>Launch</td>\n",
       "      <td>Graphics</td>\n",
       "      <td>AerialView</td>\n",
       "      <td>on board PSLV on board PSLV</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 filename category1 category2   category3  \\\n",
       "0  Video012-Scene-191.mp4    Launch  Graphics  AerialView   \n",
       "\n",
       "                       metadata  \n",
       "0  on board PSLV on board PSLV   "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  +++++++++ Loading vgg19 model++++++++++\n",
    "videopath=r\"C:\\Users\\NEERAJ SINGH\\Desktop\\Major_project\\testing videos\\Video012-Scene-191.mp4\"\n",
    "\n",
    "import os \n",
    "import cv2\n",
    "from keras.models import load_model\n",
    "from collections import deque\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "model=load_model(r\"C:\\Users\\NEERAJ SINGH\\Desktop\\Major_project\\vgg19model2.h5\")\n",
    "lb=pickle.loads(open(r\"C:\\Users\\NEERAJ SINGH\\Desktop\\Major_project\\videoclassificationtinarizer.pickle\",\"rb\").read())\n",
    "mean=np.array([123.68,116.779,103.939],dtype=\"float32\")\n",
    "Queue=deque(maxlen=220)\n",
    "# mydir=r\"C:\\Users\\NEERAJ SINGH\\Desktop\\Major_project\\testing videos\"\n",
    "# path=os.walk(mydir)\n",
    "# path=r\"C:\\Users\\NEERAJ SINGH\\Desktop\\Major_project\\testing videos\\videoplayback.mp4\"\n",
    "filelist=[]\n",
    "out =[]\n",
    "videoNo = 0\n",
    "shotNo = 0\n",
    "# filename = path\n",
    "# for(path,folders,files)in path:\n",
    "#     filepaths=[\n",
    "#         os.path.join(path,file)\n",
    "#         for file in files\n",
    "        \n",
    "        \n",
    "#     ]\n",
    "#     filelist.extend(filepaths)\n",
    "# for file in filelist:\n",
    "file=videopath\n",
    "capture_video=cv2.VideoCapture(file)\n",
    "\n",
    "file.split\n",
    "    \n",
    "outputvideo=r\"D:\\SIH_Project\\TEST VIDEO\\output.avi\"\n",
    "writer=None\n",
    "(Width,Height)=(None,None)\n",
    "count = 0\n",
    "labelList = [\n",
    "             \"AerialView\", \"AirPlane\", \"Animation\", \"Building\", \"CompositionFrame\", \n",
    "             \"Crowd\", \"DisplayScreen\",\"Forest\", \"Garden\", \"Graphics\" , \n",
    "             \"Helicopter\", \"Hospital\", \"IndoorControlRoom\" \"IndoorGeneric\", \"IndoorHome\",\n",
    "             \"IndoorLab\", \"Interview\", \"Launch\", \"Logo\", \"Mountain\", \n",
    "             \"OutdoorAntenna\", \"OutdoorGeneric\",\"OutdoorLaunchPad\",\"PersnolClosup\",\"Satellite\",\n",
    "             \"Sky\", \"Speech\", \"Text\", \"Traffic\", \"Vihicle\"\n",
    "            ]\n",
    "freq = [\n",
    "        0, 0, 0, 0, 0,\n",
    "        0, 0, 0, 0, 0,\n",
    "        0, 0, 0, 0, 0,\n",
    "        0, 0, 0, 0, 0,\n",
    "        0, 0, 0, 0, 0,\n",
    "        0, 0, 0, 0, 0\n",
    "       ]\n",
    "\n",
    "copyfreq = [\n",
    "        0, 0, 0, 0, 0,\n",
    "        0, 0, 0, 0, 0,\n",
    "        0, 0, 0, 0, 0,\n",
    "        0, 0, 0, 0, 0,\n",
    "        0, 0, 0, 0, 0,\n",
    "        0, 0, 0, 0, 0\n",
    "         ]\n",
    "\n",
    "while True:\n",
    "    (taken,frame)=capture_video.read()\n",
    "    if not taken:\n",
    "        break\n",
    "    if Width is None or Height is None:\n",
    "        (Width,Height)=frame.shape[:2]\n",
    "\n",
    "    output=frame.copy()\n",
    "    frame=cv2.cvtColor(frame,cv2.COLOR_BGR2RGB)\n",
    "    frame=cv2.resize(frame,(224,224)).astype(\"float32\")\n",
    "    frame -= mean\n",
    "    preds=model.predict(np.expand_dims(frame,axis=0))[0]\n",
    "    Queue.append(preds)\n",
    "    results=np.array(Queue).mean(axis=0)\n",
    "    i =np.argmax(results)\n",
    "    label=lb.classes_[i]\n",
    "    labelList.append(label)\n",
    "    count = count + 1\n",
    "\n",
    "    if label in labelList:\n",
    "        index = labelList.index(label)\n",
    "        freq[index] = freq[index] + 1\n",
    "        copyfreq[index] = copyfreq[index] + 1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#     text=\" category  : {}\".format(label)\n",
    "#     cv2.putText(output,text,(25,40),cv2.FONT_HERSHEY_SIMPLEX,1.25,(255,0,0),5)\n",
    "#     if writer is None:\n",
    "#         fource=cv2.VideoWriter_fourcc(*\"MJPG\")\n",
    "#         writer=cv2.VideoWriter(\"outputvideo\",fource,30,(Width,Height),True)\n",
    "#         writer.write(output)\n",
    "#         cv2.imshow(\"in progress\",output)\n",
    "#         key=cv2.waitKey(1) &0xFF\n",
    "#         if key == ord(\"q\"):\n",
    "#              break\n",
    "# release the file pointers\n",
    "# print(\"[INFO] cleaning up...\")\n",
    "# writer.release()\n",
    "freq.sort(reverse=True)\n",
    "first = freq[0]\n",
    "sec = freq[1]\n",
    "th = freq[2]\n",
    "\n",
    "fi = copyfreq.index(first)\n",
    "si = copyfreq.index(sec)\n",
    "ti = copyfreq.index(th)\n",
    "\n",
    "f = labelList[fi]\n",
    "s = labelList[si]\n",
    "t = labelList[ti]\n",
    "ans = [f, s, t]\n",
    "out.append(ans)\n",
    "\n",
    "# +++++++++++++++++++++ load NLP model +++++++++++++++++++\n",
    "\n",
    "f = open(r\"C:\\Users\\NEERAJ SINGH\\Desktop\\Major_project\\transcription.txt\", \"r+\") \n",
    "f.seek(0) \n",
    "f.truncate() \n",
    "# converting video to audio\n",
    "\n",
    "import wave, math, contextlib\n",
    "import speech_recognition as sr\n",
    "from moviepy.editor import AudioFileClip\n",
    "transcribed_audio_file_name = \"transcribed_speech.wav\"\n",
    "zoom_video_file_name =videopath\n",
    "audioclip = AudioFileClip(zoom_video_file_name)\n",
    "audioclip.write_audiofile(transcribed_audio_file_name)\n",
    "with contextlib.closing(wave.open(transcribed_audio_file_name,'r')) as f:\n",
    "    frames = f.getnframes()\n",
    "    rate = f.getframerate()\n",
    "    duration = frames / float(rate)\n",
    "total_duration = math.ceil(duration / 60)\n",
    "r = sr.Recognizer()\n",
    "for i in range(0, total_duration):\n",
    "    with sr.AudioFile(transcribed_audio_file_name) as source:\n",
    "        audio = r.record(source, offset=i*60, duration=60)\n",
    "    f = open(\"transcription.txt\", \"a\")\n",
    "    f.write(r.recognize_google(audio))\n",
    "    f.write(\" \")\n",
    "f.close()\n",
    "\n",
    "\n",
    "# taking input text from text file to python list .Â¶\n",
    "\n",
    "my_file = open(\"transcription.txt\", \"r\")\n",
    "  \n",
    "\n",
    "data = my_file.read()\n",
    "  \n",
    "\n",
    "text = data.replace('\\n', ' ').split(\".\")\n",
    "\n",
    "# print(text)\n",
    "my_file.close()\n",
    "\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "model=load_model(r\"C:\\Users\\NEERAJ SINGH\\Desktop\\Major_project\\lstm_model.h5\")\n",
    "n_most_common_words = 8000\n",
    "max_len = 130\n",
    "tokenizer = Tokenizer(num_words=n_most_common_words, filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~', lower=True)\n",
    "seq = tokenizer.texts_to_sequences(text)\n",
    "padded = pad_sequences(seq, maxlen=max_len)\n",
    "pred = model.predict(padded)\n",
    "labels =  [\n",
    "                 \"AerialView\", \"AirPlane\", \"Animation\", \"Building\", \"CompositionFrame\", \n",
    "                 \"Crowd\", \"DisplayScreen\",\"Forest\", \"Garden\", \"Graphics\" , \n",
    "                 \"Helicopter\", \"Hospital\", \"IndoorControlRoom\" \"IndoorGeneric\", \"IndoorHome\",\n",
    "                 \"IndoorLab\", \"Interview\", \"Launch\", \"Logo\", \"Mountain\", \n",
    "                 \"OutdoorAntenna\", \"OutdoorGeneric\",\"OutdoorLaunchPad\",\"PersnolClosup\",\"Satellite\",\n",
    "                 \"Sky\", \"Speech\", \"Text\", \"Traffic\", \"Vihicle\"\n",
    "                ]\n",
    "out2=[]\n",
    "x=labels[np.argmax(pred)]\n",
    "out2.append(x)\n",
    "# print(out2)\n",
    "\n",
    "# ++++++++++++= metadata generation++++++++++++++++++++\n",
    "\n",
    "# ________________________________________________________________________# audio to text _____________________________________________________________________\n",
    "import wave, math, contextlib\n",
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "import speech_recognition as sr\n",
    "from moviepy.editor import AudioFileClip\n",
    "transcribed_audio_file_name = \"transcribed_speech.wav\"\n",
    "zoom_video_file_name =videopath\n",
    "audioclip = AudioFileClip(zoom_video_file_name)\n",
    "audioclip.write_audiofile(transcribed_audio_file_name)\n",
    "with contextlib.closing(wave.open(transcribed_audio_file_name,'r')) as f:\n",
    "    frames = f.getnframes()\n",
    "    rate = f.getframerate()\n",
    "    duration = frames / float(rate)\n",
    "total_duration = math.ceil(duration / 60)\n",
    "r = sr.Recognizer()\n",
    "for i in range(0, total_duration):\n",
    "    with sr.AudioFile(transcribed_audio_file_name) as source:\n",
    "        audio = r.record(source, offset=i*60, duration=60)\n",
    "    f = open(\"transcription.txt\", \"a\")\n",
    "    f.write(r.recognize_google(audio))\n",
    "    f.write(\" \")\n",
    "f.close()\n",
    "# text file to list \n",
    "\n",
    "my_file = open(\"transcription.txt\", \"r\")\n",
    "  \n",
    "\n",
    "data = my_file.read()\n",
    "  \n",
    "\n",
    "text = data.replace('\\n', ' ').split(\".\")\n",
    "metadata=text\n",
    "\n",
    "\n",
    "#  +++++++++++++++++++compairing output of vgg19 model and nlp model and predicting final output++++++++++++++++++++++\n",
    "for i in range(3):\n",
    "    if out2 in out:\n",
    "        category=out2[0]\n",
    "    else:\n",
    "        category=out[0]\n",
    "print(category)\n",
    "print(metadata)\n",
    "\n",
    "import pandas as pd\n",
    "d=pd.DataFrame(np.array(out),columns=[\"category1\", \"category2\", \"category3\"])\n",
    "writer = pd.ExcelWriter(\"test.xlsx\")\n",
    "d.to_excel(writer)\n",
    "writer.save()\n",
    "path_list = videopath.split(os.sep)\n",
    "x=path_list[6]\n",
    "df = pd.read_excel(r\"C:\\Users\\NEERAJ SINGH\\Desktop\\Major_project\\test.xlsx\")\n",
    "df.insert(4, \"metadata\", np.array(metadata))\n",
    "df.insert(1, \"filename\", np.array(x))\n",
    "df.drop(\"Unnamed: 0\",axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5acdbaa6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f17ec7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
